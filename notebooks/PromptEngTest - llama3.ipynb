{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f83b3c1e-2129-424a-b2b7-0677418ac1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x18695058030>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Llama3 for Inference\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "630c3c20-3f90-457b-ae7d-caee47a31fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "# Create a BitsAndBytesConfig object with your desired settings\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a835a4f3-ae34-40c2-929e-63da0cea821c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165c4658dcd949fb9e75bdba8d8da62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Meta-Llama-3-8B\", \n",
    "    device_map=\"auto\", \n",
    "    torch_dtype=\"auto\", \n",
    "    #trust_remote_code=True, \n",
    "    quantization_config=quant_config\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b6278d5-d2d2-49ea-a539-069d245fdab4",
   "metadata": {},
   "source": [
    "Generate in json format various variations of the linux command ls. Also provide an example of the output. The server is used in a hospital so generate hopital relevant output\n",
    "\n",
    "The format should be like the following but in JSON format\n",
    "command: ls\n",
    "example: a.txt b.txt f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c575451f-c52d-46bf-b53c-20f874e1d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_cmd_examples = [\n",
    "    {\n",
    "        \"user\": \"last\",\n",
    "        \"example\": \"john   pts/1        192.168.1.10    Mon Jul  8 10:30   still logged in\\njane   pts/2        192.168.1.11    Mon Jul  8 09:45   gone - no logout\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"last -a\",\n",
    "        \"example\": \"john   pts/1        192.168.1.10    Mon Jul  8 10:30   still logged in\\njane   pts/2        192.168.1.11    Mon Jul  8 09:45   gone - no logout\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"last -i\",\n",
    "        \"example\": \"john   pts/1        192.168.1.10\\njane   pts/2        192.168.1.11\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"last -F\",\n",
    "        \"example\": \"john   pts/1        192.168.1.10    Mon Jul  8 10:30:45 2024   still logged in\\njane   pts/2        192.168.1.11    Mon Jul  8 09:45:12 2024   gone - no logout\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"last -R\",\n",
    "        \"example\": \"john   pts/1        192.168.1.10    Mon Jul  8 10:30   still logged in\\njane   pts/2        192.168.1.11    Mon Jul  8 09:45   gone - no logout\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"last -x\",\n",
    "        \"example\": \"john   pts/1        192.168.1.10    Mon Jul  8 10:30   still logged in\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "nc_cmd_examples = [\n",
    "    {\n",
    "        \"user\": \"nc\",\n",
    "        \"example\": \"Connected to hospital-server.local on port 80\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"nc -l\",\n",
    "        \"example\": \"Listening on port 8080 for incoming connections\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"nc -v hospital-server.local 443\",\n",
    "        \"example\": \"Connection to hospital-server.local 443 succeeded\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"nc -u -l 1234\",\n",
    "        \"example\": \"Listening on UDP port 1234\"\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"nc -zv hospital-db.local 3306\",\n",
    "        \"example\": \"Connection to hospital-db.local 3306 succeeded\"\n",
    "    }\n",
    "]\n",
    "\n",
    "netstat_cmd_examples = [\n",
    "    {\n",
    "        \"command\": \"netstat\",\n",
    "        \"example\": \"Active Internet connections (w/o servers)\\nProto Recv-Q Send-Q Local Address           Foreign Address         State\\ntcp        0      0 192.168.1.10:34567      203.0.113.1:https       ESTABLISHED\\nudp        0      0 0.0.0.0:123              0.0.0.0:*\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"netstat -a\",\n",
    "        \"example\": \"Active Internet connections (servers and established)\\nProto Recv-Q Send-Q Local Address           Foreign Address         State\\ntcp        0      0 *:ssh                   *:*                     LISTEN\\ntcp        0      0 localhost:smtp          *:*                     LISTEN\\nudp        0      0 *:123                   *:*\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"netstat -l\",\n",
    "        \"example\": \"Active Internet connections (only servers)\\nProto Recv-Q Send-Q Local Address           Foreign Address         State\\ntcp        0      0 *:ssh                   *:*                     LISTEN\\nudp        0      0 *:123                   *:*\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"netstat -p\",\n",
    "        \"example\": \"Active Internet connections (w/o servers)\\nProto Recv-Q Send-Q Local Address           Foreign Address         State\\ntcp        0      0 192.168.1.10:34567      203.0.113.1:https       ESTABLISHED\\nudp        0      0 0.0.0.0:123              0.0.0.0:*\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"netstat -n\",\n",
    "        \"example\": \"Active Internet connections (w/o servers)\\nProto Recv-Q Send-Q Local Address           Foreign Address         State\\ntcp        0      0 192.168.1.10:34567      203.0.113.1:443         ESTABLISHED\\nudp        0      0 0.0.0.0:123              0.0.0.0:*\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"netstat -r\",\n",
    "        \"example\": \"Kernel IP routing table\\nDestination     Gateway         Genmask         Flags   MSS Window  irtt Iface\\ndefault         router          0.0.0.0         UG        0 0          0 eth0\\n192.168.1.0     0.0.0.0         255.255.255.0   U         0 0          0 eth0\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"netstat -s\",\n",
    "        \"example\": \"Ip:\\n    12345 total packets received\\n    0 forwarded\\n    0 incoming packets discarded\\n    0 incoming packets discarded\\n    0 incoming packets discarded\\n    0 fragments dropped after final reassembly\\n    0 fragments dropped after final reassembly\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "nohup_cmd_examples = [\n",
    "    {\n",
    "        \"command\": \"nohup command &\",\n",
    "        \"example\": \"nohup python patient_monitor.py &\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"nohup command > output.log &\",\n",
    "        \"example\": \"nohup bash schedule_generator.sh > schedule.log &\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"nohup command > output.log 2>&1 &\",\n",
    "        \"example\": \"nohup ./patient_report.sh > patient_report.log 2>&1 &\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"nohup command -p PID &\",\n",
    "        \"example\": \"nohup java -jar hospital_mgmt.jar -p 1234 &\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "scp_cmd_examples =[\n",
    "    {\n",
    "        \"command\": \"scp\",\n",
    "        \"example\": \"patients.txt user@example.com:/home/remote_user/data\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"scp -r\",\n",
    "        \"example\": \"records/ user@example.com:/backup\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"scp -P\",\n",
    "        \"example\": \"patients.txt -P 2222 user@example.com:/home/remote_user/data\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"scp -v\",\n",
    "        \"example\": \"patients.txt user@example.com:/home/remote_user/data\\nDebugging connection...\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"scp -i\",\n",
    "        \"example\": \"patients.txt -i ~/.ssh/hospital_key user@example.com:/home/remote_user/data\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"scp -B\",\n",
    "        \"example\": \"patients.txt user@example.com:/backup\\nBackground transfer initiated.\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"scp -C\",\n",
    "        \"example\": \"patients.txt user@example.com:/home/remote_user/data\\nCompression enabled.\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"scp -l\",\n",
    "        \"example\": \"patients.txt -l 5000 user@example.com:/home/remote_user/data\\nLimited bandwidth transfer.\"\n",
    "    }]\n",
    "\n",
    "\n",
    "service_cmd_examples = [\n",
    "    {\n",
    "        \"command\": \"service\",\n",
    "        \"example\": \"apache2 start\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"service apache2 status\",\n",
    "        \"example\": \"â— apache2.service - The Apache HTTP Server\\n   Loaded: loaded (/lib/systemd/system/apache2.service; enabled; vendor preset: enabled)\\n   Active: active (running) since Mon 2024-07-08 10:00:00 UTC; 1h ago\\n     Docs: https://httpd.apache.org/docs/2.4/\\n Main PID: 12345 (apache2)\\n    Tasks: 55 (limit: 512)\\n   Memory: 150.0M\\n   CGroup: /system.slice/apache2.service\\n           â”œâ”€12345 /usr/sbin/apache2 -k start\\n           â”œâ”€12346 /usr/sbin/apache2 -k start\\n           â””â”€12347 /usr/sbin/apache2 -k start\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"service mysql start\",\n",
    "        \"example\": \"Starting MySQL database server: mysqld.\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"service nginx restart\",\n",
    "        \"example\": \"Restarting nginx (via systemctl): nginx.service.\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"service --status-all\",\n",
    "        \"example\": \" [ + ]  apache2\\n [ - ]  mysql\\n [ ? ]  nginx\"\n",
    "    }\n",
    "]\n",
    "\n",
    "tftp_cmd_examples = [\n",
    "    {\n",
    "        \"command\": \"tftp\",\n",
    "        \"example\": \"Usage: tftp [OPTION]... HOST [PORT]\\n\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"tftp -c get patients.txt\",\n",
    "        \"example\": \"Received 2048 bytes in 0.1 seconds\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"tftp -c put doctors.txt\",\n",
    "        \"example\": \"Sent 4096 bytes in 0.2 seconds\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"tftp -m binary -c get schedule.csv\",\n",
    "        \"example\": \"Received 1024 bytes in 0.1 seconds\"\n",
    "    }\n",
    "]\n",
    "\n",
    "ulimit_cmd_examples = [\n",
    "    {\n",
    "        \"command\": \"ulimit\",\n",
    "        \"example\": \"unlimited\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"ulimit -a\",\n",
    "        \"example\": \"core file size          (blocks, -c) 0\\ndata seg size           (kbytes, -d) unlimited\\nscheduling priority             (-e) 0\\nfile size               (blocks, -f) unlimited\\npending signals                 (-i) 31529\\nmax locked memory       (kbytes, -l) 64\\nmax memory size         (kbytes, -m) unlimited\\nopen files                      (-n) 1024\\npipe size            (512 bytes, -p) 8\\nPOSIX message queues     (bytes, -q) 819200\\nreal-time priority              (-r) 0\\nstack size              (kbytes, -s) 8192\\ncpu time               (seconds, -t) unlimited\\nmax user processes              (-u) 31529\\nvirtual memory          (kbytes, -v) unlimited\\nfile locks                      (-x) unlimited\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"ulimit -c\",\n",
    "        \"example\": \"0\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"ulimit -u\",\n",
    "        \"example\": \"31529\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"ulimit -n\",\n",
    "        \"example\": \"1024\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "unzip_cmd_examples = [\n",
    "    {\n",
    "        \"command\": \"unzip\",\n",
    "        \"example\": \"patient_records.zip\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"unzip -l\",\n",
    "        \"example\": \"    2048  2024-07-08 09:00   patients/patient1.txt\\n    4096  2024-07-08 09:00   patients/patient2.txt\\n    1024  2024-07-08 09:00   schedule/schedule.csv\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"unzip -t\",\n",
    "        \"example\": \"No errors detected in compressed data of patient_records.zip.\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"unzip -d\",\n",
    "        \"example\": \"Extracting to directory 'patient_records/'\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"unzip -o\",\n",
    "        \"example\": \"Overwrite existing files without prompting.\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"unzip -q\",\n",
    "        \"example\": \"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "wget_cmd_examples = [\n",
    "    {\n",
    "        \"command\": \"wget https://example.com/patients.csv\",\n",
    "        \"example\": \"--2024-07-08 10:00:00--  https://example.com/patients.csv\\n\" +\n",
    "                   \"Resolving example.com (example.com)... 192.0.2.1\\n\" +\n",
    "                   \"Connecting to example.com (example.com)|192.0.2.1|:443... connected.\\n\" +\n",
    "                   \"HTTP request sent, awaiting response... 200 OK\\n\" +\n",
    "                   \"Length: 2048 (2.0K) [text/csv]\\n\" +\n",
    "                   \"Saving to: â€˜patients.csvâ€™\\n\\n\" +\n",
    "                   \"100%[======================================>] 2,048       --.-K/s   in 0.001s\\n\\n\" +\n",
    "                   \"2024-07-08 10:00:01 (2.00 MB/s) - â€˜patients.csvâ€™ saved [2048/2048]\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"wget -r -np -nH --cut-dirs=1 ftp://example.com/records/\",\n",
    "        \"example\": \"--2024-07-08 10:05:00--  ftp://example.com/records/\\n\" +\n",
    "                   \"           => â€˜example.com/records/index.htmlâ€™\\n\" +\n",
    "                   \"Resolving example.com (example.com)... 192.0.2.1\\n\" +\n",
    "                   \"Connecting to example.com (example.com)|192.0.2.1|:21... connected.\\n\" +\n",
    "                   \"Logging in as anonymous ... Logged in!\\n\" +\n",
    "                   \"==> SYST ... done.    ==> PWD ... done.\\n\" +\n",
    "                   \"==> TYPE I ... done.  ==> CWD /records ... done.\\n\" +\n",
    "                   \"==> PASV ... done.    ==> LIST ... done.\\n\" +\n",
    "                   \"Mode ...                \\n\" +\n",
    "                   \"Length ...              \\n\" +\n",
    "                   \"Saving to: â€˜example.com/records/index.htmlâ€™\\n\" +\n",
    "                   \"\\n\" +\n",
    "                   \"     [ <=>                                   ] 2,048       --.-K/s   in 0.001s\\n\\n\" +\n",
    "                   \"2024-07-08 10:05:01 (2.00 MB/s) - â€˜example.com/records/index.htmlâ€™ saved [2048]\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"wget -qO- https://example.com/doctors.txt\",\n",
    "        \"example\": \"Dr. John Doe\\nDr. Jane Smith\\nDr. Michael Johnson\\n\"\n",
    "    }\n",
    "]\n",
    "\n",
    "yum_cms_examples = [\n",
    "    {\n",
    "        \"command\": \"yum\",\n",
    "        \"example\": \"Installed Packages:\\nhealthcare-app-1.2.3-1.el7.x86_64\\nmedication-db-2024.1-1.el7.noarch\\nAvailable Packages:\\nhealthcare-app-1.2.4-1.el7.x86_64\\nemergency-kit-1.0-1.el7.noarch\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"yum list\",\n",
    "        \"example\": \"Installed Packages:\\nhealthcare-app-1.2.3-1.el7.x86_64\\nmedication-db-2024.1-1.el7.noarch\\nAvailable Packages:\\nhealthcare-app-1.2.4-1.el7.x86_64\\nemergency-kit-1.0-1.el7.noarch\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"yum install healthcare-app\",\n",
    "        \"example\": \"Loaded plugins: fastestmirror\\nLoading mirror speeds from cached hostfile\\nResolving Dependencies\\n--> Running transaction check\\n---> Package healthcare-app.x86_64 0:1.2.4-1.el7 will be installed\\n--> Finished Dependency Resolution\\n\\nDependencies Resolved\\n\\n====================================================================================================\\n Package           Arch             Version                Repository                           Size\\n====================================================================================================\\nInstalling:\\n healthcare-app    x86_64           1.2.4-1.el7            hospital-repo                       10 M\\n\\nTransaction Summary\\n====================================================================================================\\nInstall  1 Package\\n\\nTotal download size: 10 M\\nInstalled size: 20 M\\nIs this ok [y/d/N]: y\\nDownloading packages:\\nRunning transaction check\\nRunning transaction test\\nTransaction test succeeded\\nRunning transaction\\n  Installing : healthcare-app-1.2.4-1.el7.x86_64                                                  1/1 \\n  Verifying  : healthcare-app-1.2.4-1.el7.x86_64                                                  1/1 \\n\\nInstalled:\\n  healthcare-app.x86_64 0:1.2.4-1.el7                                                               \\n\\nComplete!\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"yum update\",\n",
    "        \"example\": \"Loaded plugins: fastestmirror\\nLoading mirror speeds from cached hostfile\\nNo packages marked for update\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"yum remove medication-db\",\n",
    "        \"example\": \"Loaded plugins: fastestmirror\\nResolving Dependencies\\n--> Running transaction check\\n---> Package medication-db.noarch 0:2024.1-1.el7 will be erased\\n--> Finished Dependency Resolution\\n\\nDependencies Resolved\\n\\n====================================================================================================\\n Package             Arch             Version                  Repository                         Size\\n====================================================================================================\\nRemoving:\\n medication-db       noarch           2024.1-1.el7             @hospital-repo                    5.0 k\\n\\nTransaction Summary\\n====================================================================================================\\nRemove  1 Package\\n\\nInstalled size: 5.0 k\\nIs this ok [y/N]: y\\nDownloading packages:\\nRunning transaction check\\nRunning transaction test\\nTransaction test succeeded\\nRunning transaction\\n  Erasing    : medication-db-2024.1-1.el7.noarch                                                1/1 \\n  Verifying  : medication-db-2024.1-1.el7.noarch                                                1/1 \\n\\nRemoved:\\n  medication-db.noarch 0:2024.1-1.el7                                                           \\n\\nComplete!\"\n",
    "    },\n",
    "    {\n",
    "        \"command\": \"yum search emergency\",\n",
    "        \"example\": \"Loaded plugins: fastestmirror\\nLoading mirror speeds from cached hostfile\\n=============================== N/S matched: emergency ===============================\\nemergency-kit.noarch : Emergency kit for hospital facilities\\n\\n  Name and summary matches only, use 'search all' for everything.\\n\"\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33c66294-211e-4bb2-b684-ac447dcac0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "command_examples_list =  [\n",
    "    nc_cmd_examples,\n",
    "    netstat_cmd_examples,\n",
    "    nohup_cmd_examples,\n",
    "    scp_cmd_examples,\n",
    "    service_cmd_examples,\n",
    "    tftp_cmd_examples,\n",
    "    ulimit_cmd_examples,\n",
    "    unzip_cmd_examples,\n",
    "    wget_cmd_examples,\n",
    "    yum_cms_examples,\n",
    "    last_cmd_examples\n",
    "                         ]\n",
    "\n",
    "command_example =[unzip_cmd_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112b3242-5daf-4b92-880b-5e19763bb383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dbcf91a-b909-4456-b853-e4f89f8070b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_str = \"You are Linux OS terminal for a server containing sensitive patient data.\" \\\n",
    "          \"Your personality is: You are a Linux OS terminal. You act and respond exactly as a Linux terminal.\" \\\n",
    "          \"You will respond to all commands just as a Linux terminal would.\" \\\n",
    "          \"You can only respond to user inputs and you must not write any commands on your own.\" \\\n",
    "          \"You must not in any case have a conversation with user as a chatbot and must not explain your output and do not repeat commands user inputs.\" \\\n",
    "          \"Do not explain to user what they are seeing. Only respond as Linux terminal.\" \\\n",
    "          \"You will need to make up realistic answers to the command, as they would be returned by a real linux terminal for a hospital server.\" \\\n",
    "          \"It is very important that you do not name files and directiories file1.txt file2.txt file3.txt or similarly, rather create plausible file names for a real terminal with patient data.\"\n",
    "\n",
    "\n",
    "#system_str = \"You are a Linux Server in a hospital. Output a response for the given command input.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83448846-7cba-4957-b743-072e742f720d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has multiple chat templates with no default specified! Please either pass a chat template or the name of the template you wish to use to the `chat_template` argument. Available template names are ['messages'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 25\u001b[0m\n\u001b[0;32m     11\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     14\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m     15\u001b[0m     chat_template\u001b[38;5;241m=\u001b[39mchat_template\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m generation_args \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_new_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m600\u001b[39m,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_full_text\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.3\u001b[39m,\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_sample\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     23\u001b[0m }\n\u001b[1;32m---> 25\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\lib\\site-packages\\transformers\\pipelines\\text_generation.py:258\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[1;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    254\u001b[0m     text_inputs, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, KeyDataset) \u001b[38;5;28;01mif\u001b[39;00m is_torch_available() \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[0;32m    255\u001b[0m ) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text_inputs[\u001b[38;5;241m0\u001b[39m], (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;66;03m# We have one or more prompts in list-of-dicts format, so this is chat mode\u001b[39;00m\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text_inputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 258\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mChat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    260\u001b[0m         chats \u001b[38;5;241m=\u001b[39m [Chat(chat) \u001b[38;5;28;01mfor\u001b[39;00m chat \u001b[38;5;129;01min\u001b[39;00m text_inputs]  \u001b[38;5;66;03m# ðŸˆ ðŸˆ ðŸˆ\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\lib\\site-packages\\transformers\\pipelines\\base.py:1243\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1236\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1237\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1240\u001b[0m         )\n\u001b[0;32m   1241\u001b[0m     )\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\lib\\site-packages\\transformers\\pipelines\\base.py:1249\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m-> 1249\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1250\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\lib\\site-packages\\transformers\\pipelines\\text_generation.py:277\u001b[0m, in \u001b[0;36mTextGenerationPipeline.preprocess\u001b[1;34m(self, prompt_text, prefix, handle_long_generation, add_special_tokens, truncation, padding, max_length, **generate_kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    267\u001b[0m     prompt_text,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs,\n\u001b[0;32m    275\u001b[0m ):\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompt_text, Chat):\n\u001b[1;32m--> 277\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_chat_template\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprompt_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m            \u001b[49m\u001b[43madd_generation_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    287\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(\n\u001b[0;32m    288\u001b[0m             prefix \u001b[38;5;241m+\u001b[39m prompt_text,\n\u001b[0;32m    289\u001b[0m             truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    293\u001b[0m             return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework,\n\u001b[0;32m    294\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cuda_env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1771\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.apply_chat_template\u001b[1;34m(self, conversation, chat_template, add_generation_prompt, tokenize, padding, truncation, max_length, return_tensors, return_dict, tokenizer_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1769\u001b[0m             using_default_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1770\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m chat_template \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1771\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1772\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has multiple chat templates with no default specified! Please either pass a chat \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1773\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemplate or the name of the template you wish to use to the `chat_template` argument. Available \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1774\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemplate names are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(template_dict\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1775\u001b[0m         )\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m chat_template \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1777\u001b[0m     \u001b[38;5;66;03m# These are the cases when the model has a single template\u001b[39;00m\n\u001b[0;32m   1778\u001b[0m     \u001b[38;5;66;03m# priority: `chat_template` argument > `tokenizer.chat_template` > `tokenizer.default_chat_template\u001b[39;00m\n\u001b[0;32m   1779\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_template \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: This model has multiple chat templates with no default specified! Please either pass a chat template or the name of the template you wish to use to the `chat_template` argument. Available template names are ['messages']."
     ]
    }
   ],
   "source": [
    "\n",
    "for command_examples in command_examples_list:\n",
    "    for command_example in command_examples:\n",
    "\n",
    "        content_str = command_example['command'] + \" Use the following as an example for the output. \" +  command_example['example']\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_str},\n",
    "            {\"role\": \"user\", \"content\": command_example['command'] }\n",
    "        ]\n",
    "        \n",
    "        pipe = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            chat_template=chat_template\n",
    "        )\n",
    "        \n",
    "        generation_args = {\n",
    "            \"max_new_tokens\": 600,\n",
    "            \"return_full_text\": False,\n",
    "            \"temperature\": 0.3,\n",
    "            \"do_sample\": False,\n",
    "        }\n",
    "        \n",
    "        output = pipe(messages, **generation_args)\n",
    "        \n",
    "        print(\"---------------------------------------------------------\")\n",
    "        print(\"User\")\n",
    "        print(command_example['command'])\n",
    "        print(\"Assistant\")\n",
    "        print(output[0]['generated_text'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a3f1a1-cb9b-4c3f-a784-769b5e21286d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cuda_env)",
   "language": "python",
   "name": "cuda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
